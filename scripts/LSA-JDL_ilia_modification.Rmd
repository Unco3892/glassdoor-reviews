---
title: "Embedding-JDL"
output: html_document
---


```{r , include=FALSE}
# Loading packages and knitr options
source(here::here("scripts/setup.R"))

library(lexicon)
library(ngram)
library(ranger)
```


```{r, include=FALSE}
# Importing the data
bank_reviews <-
  read_csv(here::here("data/Bank_reviews_processed.csv"))

# Apply a filter to remove the duplicated entries and also add sentiments separately for pros and con which we will combine later. The word count was also added
bank_reviews %<>%
  filter(!duplicated(review_id)) %>%
  dplyr::mutate(
    pro_sen_score = sentimentr::sentiment_by(text.var = get_sentences(employer_pros))$ave_sentiment,
    # we did not use the sentiment function as it gave some recycling issues. We use get_sentences to avoid warnings but it is not necessary
    cons_sen_score = sentimentr::sentiment_by(get_sentences(employer_cons))$ave_sentiment,
    pros_w_count = str_count(employer_pros, '\\w+'),
    cons_w_count = str_count(employer_cons, '\\w+')
  )

# Corpus creation for pros
corpus.pros <- corpus(x = bank_reviews,
                      text_field = c("employer_pros"))

# Corpus creation for pros
corpus.cons <- corpus(x = bank_reviews,
                      text_field = c("employer_cons"))
```

```{r}
# tokens for pros
tokenize_reviews <- function(a_corpus) {
  tokens.pros <- quanteda::tokens(
    a_corpus,
    remove_punct = TRUE,
    remove_symbols = TRUE,
    remove_url = TRUE
  ) %>%
    tokens_tolower() %>%
    tokens_remove(
      c(
        "bank",
        "ubs",
        "jpmorgan",
        "hsbc",
        "td",
        "deutsche" ,
        "#name",
        "good",
        "great",
        stopwords("english")
      )
    ) %>%
    tokens_replace(pattern = hash_lemmas$token, replacement = hash_lemmas$lemma)
}

# tokens for pros
tokens.pros <- tokenize_reviews(corpus.pros)

# tokens for cons
tokens.cons <- tokenize_reviews(corpus.cons)
```


```{r}
#Plotting
hist(ntoken(tokens.pros), breaks = 200)

hist(ntoken(tokens.cons), breaks = 200)
```


```{r}
# Keeping reviews with more than a certain number of token for pros & cons
min.token <- 10

tokens.pros.clean <- tokens.pros %>%
  tokens_subset(ntoken(tokens.pros) > min.token & ntoken(tokens.cons) > min.token)

tokens.cons.clean <- tokens.cons %>%
  tokens_subset(ntoken(tokens.cons) > min.token & ntoken(tokens.pros) > min.token)
```


```{r}
# dfm pros
dfm.pros <- dfm(tokens.pros.clean)

# dfm cos
dfm.cons <- dfm(tokens.cons.clean)

# tfidf pros
tfidf.pros <- dfm_tfidf(dfm.pros)

# tfidf cons
tfidf.cons <- dfm_tfidf(dfm.cons)
```


```{r}
# Retrieving the ratings
y <- docvars(tokens.pros.clean, "employer_rating")

# Selecting the candidates for the number of dimensions
nd.vec <- c(5,20,30,50)

# Creating the training Set
set.seed(123)
index.tr <- sample(size=round(0.8*length(y)), x=c(1:length(y)), replace=FALSE)
```


# DTM
```{r}
# Creating a result matrix for lm
rmse.lm.dtm <- matrix(nrow = length(nd.vec), ncol = length(nd.vec))
rownames(rmse.lm.dtm) <- nd.vec
colnames(rmse.lm.dtm) <- nd.vec

# Creating a result matrix for rf
rmse.rf.dtm <- matrix(nrow = length(nd.vec), ncol = length(nd.vec))
rownames(rmse.rf.dtm) <- nd.vec
colnames(rmse.rf.dtm) <- nd.vec

# Compute the RMSE for each combination of #Topic for pros and cons
for (i in 1:length(nd.vec)){
  for (j in 1:length(nd.vec)){
  
  #LSA
  lsa.pros <- textmodel_lsa(dfm.pros, nd=nd.vec[i])
  lsa.cons <- textmodel_lsa(dfm.cons, nd=nd.vec[j])
  # df <- data.frame(Score=y, X1=lsa.pros$docs, X2=lsa.cons$docs)
  
  df <- data.frame(
  Score = y,
  X1 = lsa.pros$docs,
  X2 = lsa.cons$docs,
  total_sen_score = rowSums(docvars(
    tokens.pros.clean, c("pro_sen_score", "cons_sen_score")
  )))

    
  df.tr <- df[index.tr,]
  df.te <- df[-index.tr,]
  
  set.seed(100)
  #LM
  reviews.lm <- lm(Score ~ .,
                   data = df.tr)
  pred.lm <- predict(reviews.lm, df.te)
  pred.lm <- pmin(5, predict(reviews.lm, df.te))
  rmse.lm.dtm[i, j] <- sqrt(mean((pred.lm - df.te$Score) ^ 2)) 
  
  #RF
  reviews.rf <- ranger(Score ~ .,
                       data = df.tr)
  pred.rf <- predict(reviews.rf, df.te)$predictions
  rmse.rf.dtm[i, j] <- sqrt(mean((pred.rf - df.te$Score) ^ 2))
  }
}

min(rmse.lm.dtm)
min(rmse.rf.dtm)
```

# TFIDF

```{r}
# Creating a result matrix for ls
rmse.lm.tfidf <- matrix(nrow = length(nd.vec), ncol = length(nd.vec))
rownames(rmse.lm.tfidf) <- nd.vec
colnames(rmse.lm.tfidf) <- nd.vec

# Creating a result matrix for rf
rmse.rf.tfidf <- matrix(nrow = length(nd.vec), ncol = length(nd.vec))
rownames(rmse.rf.tfidf) <- nd.vec
colnames(rmse.rf.tfidf) <- nd.vec

# Compute the RMSE for each combination of #Topic for pros and cons
for (i in 1:length(nd.vec)){
  for (j in 1:length(nd.vec)){
  
  #LSA
  lsa.pros <- textmodel_lsa(tfidf.pros, nd=nd.vec[i])
  lsa.cons <- textmodel_lsa(tfidf.cons, nd=nd.vec[j])
  # df <- data.frame(Score=y, X1=lsa.pros$docs, X2=lsa.cons$docs)
  
  df <- data.frame(
  Score = y,
  X1 = lsa.pros$docs,
  X2 = lsa.cons$docs,
  total_sen_score = rowSums(docvars(
    tokens.pros.clean, c("pro_sen_score", "cons_sen_score")))
    # total_word_count = rowMeans(docvars(
    #     tokens.pros.clean, c("pros_w_count", "cons_w_count")
  )
  
  df.tr <- df[index.tr,]
  df.te <- df[-index.tr,]
  
  set.seed(100)
  #LM
  reviews.lm <- lm(Score ~ .,
                   data = df.tr)
  pred.lm <- predict(reviews.lm, df.te)
  pred.lm <- pmin(5, predict(reviews.lm, df.te))
  rmse.lm.tfidf[i, j] <- sqrt(mean((pred.lm - df.te$Score) ^ 2))

  #RF
  reviews.rf <- ranger(Score ~ .,
                       data = df.tr)
  pred.rf <- predict(reviews.rf, df.te)$predictions
  rmse.rf.tfidf[i, j] <- sqrt(mean((pred.rf - df.te$Score) ^ 2))
  }
}

min(rmse.lm.tfidf)
min(rmse.rf.tfidf)
```

Could add the valence shifters to the combination as well as the log count for the cons.

# Best model (TF-IDF + LSA)
We can also the valence shifter and the long length of the reviews to it.

```{r}
lsa.pros <- textmodel_lsa(tfidf.pros, nd = 20)
# lsa.cons <- textmodel_lsa(tfidf.cons, nd = 20)
# Even better for the cons to be 30
lsa.cons <- textmodel_lsa(tfidf.cons, nd = 5)
df <- data.frame(
  Score = y,
  X1 = lsa.pros$docs,
  X2 = lsa.cons$docs,
  # Note that in the code below, we can use either tokens.pros.clean or tokens.cons.clean as they both contain the same sentiment and word count columns
  total_sen_score = rowSums(docvars(
    tokens.pros.clean, c("pro_sen_score", "cons_sen_score")
  )))

df.tr <- df[index.tr, ]
df.te <- df[-index.tr, ]

#RF
set.seed(100)
reviews.rf <- ranger(Score ~ .,
                     data = df.tr,
                     importance = "impurity")
pred.rf <- predict(reviews.rf, df.te)$predictions


rmse <- sqrt(mean((pred.rf - df.te$Score)^2))
rmse
# 0.991 however it does not look as good as the LSA one
plot(pred.rf ~ df.te$Score, ylab="Predictions", xlab="Observed", pch=20)
```
What worked well and what didn't:
- Without the log for both combined looks better it looks better
- Taking the log10 of just pros_w_count is slightly better than the other models but not much and does not make much sense.
- Taking the mean of the rows instead of the sum did not work either
- Having only the sentiments is enough, also don't forget to set seed

## Word Embedding & Glove
Here we will also try to model using embedding and glove

The glove below can take 5 minutes or more depending on the computer that you have so please run with caution!

```{r}
# Tried windows 5,4,3 and 4 seems reasonable
tokens.pros.clean_fcm <- fcm(
  tokens.pros.clean,
  context = "window",
  count = "weighted",
  window = 4,
  weights = 1 / (1:4),
  tri = FALSE
)

# with embedding for cons
tokens.cons.clean_fcm <- fcm(
  tokens.cons.clean,
  context = "window",
  count = "weighted",
  window = 4,
  weights = 1 / (1:4),
  tri = FALSE
)

# Selecting the candidates for the number of embedding dimensions
# for trial run this:
nd.vec <- c(5,20,50)

# Creating a result matrix for rf
rmse.rf.tfidf <-
  matrix(nrow = length(nd.vec), ncol = length(nd.vec))
rownames(rmse.rf.tfidf) <- nd.vec
colnames(rmse.rf.tfidf) <- nd.vec

# Compute the RMSE for each combination of #Topic for pros and cons
for (i in 1:length(nd.vec)) {
  for (j in 1:length(nd.vec)) {
    # Giving dimensions to the embedding
    glove_pros <- GlobalVectors$new(rank = nd.vec[i], x_max = 1)
    glove_cons <- GlobalVectors$new(rank = nd.vec[j], x_max = 1)
    
    # fitting the model, with the targets in mind
    word_vectors_main_pro <-
      glove_pros$fit_transform(tokens.pros.clean_fcm, n_iter = 100)
    print(paste("Iteration for pros at:",nd.vec[i]))
    
    word_vectors_main_cons <-
      glove_cons$fit_transform(tokens.cons.clean_fcm, n_iter = 100)
    print(paste("Iteration for cons at:",nd.vec[j]))

    # Taking out the context of the model
    word_vectors_context_pros <- glove_pros$components
    word_vectors_context_cons <- glove_cons$components
    
    # Adding the target + transpose of the context words
    reviews_glove_pro <-
      word_vectors_main_pro + t(word_vectors_context_pros)
    reviews_glove_con <-
      word_vectors_main_cons + t(word_vectors_context_cons)
    
    # number of documents which is the same for both
    ndoc <- length(tokens.pros.clean)
    
    # looking at the centers of pros and cons
    centers_pros <-
      matrix(nr = ndoc, nc = nd.vec[i]) # document embedding matrix
    centers_cons <-
      matrix(nr = ndoc, nc = nd.vec[j]) # document embedding matrix
    
    for (f in 1:ndoc) {
      words_in_f_p <-
        reviews_glove_pro[tokens.pros.clean[[f]], , drop = FALSE]
      
      centers_pros[f, ] <- apply(words_in_f_p, 2, mean)
      
      words_in_f_c <-
        reviews_glove_con[tokens.cons.clean[[f]], , drop = FALSE]
      
      centers_cons[f, ] <- apply(words_in_f_c, 2, mean)
    }
    
    row.names(centers_pros) <- names(tokens.pros.clean)
    row.names(centers_cons) <- names(tokens.cons.clean)
    
    df <- data.frame(
      Score = y,
      X1 = centers_pros,
      X2 = centers_cons,
      total_sen_score = rowSums(docvars(
        tokens.pros.clean, c("pro_sen_score", "cons_sen_score")
      )),
      total_word_count = rowMeans(docvars(
        tokens.pros.clean, c("pros_w_count", "cons_w_count")
      ))) #here we take the mean words instead of the sum as it worked better
    
    df.tr <- df[index.tr, ]
    df.te <- df[-index.tr, ]

    #RF
    reviews.rf <- ranger(Score ~ .,
                         data = df.tr)
    pred.rf <- predict(reviews.rf, df.te)$predictions
    rmse.rf.tfidf[i, j] <- sqrt(mean((pred.rf - df.te$Score) ^ 2))
  }
}

min(rmse.rf.tfidf)
```

# Best combination seems to be i = 20 and j= 20 with rmse of 0.921 for window of 4 words with both sentiment and mean of the word counts

Topic importance

```{r}
reviews.rf$variable.importance


imp <- data.frame(keyName=names(reviews.rf$variable.importance), value=reviews.rf$variable.importance, row.names=NULL)

imp$type[1:50] <- "pros"
imp$type[31:50] <- "cons"
```


```{r}
imp %>%
  mutate(name = fct_reorder(keyName, value)) %>%
  ggplot(aes(x = name, y = value, fill = type)) +
  geom_bar(stat = "identity",
           alpha = .6,
           width = .4) +
  coord_flip() +
  xlab("") +
  ylab("impurity") +
  theme_bw()
```

```{r}
topic16 <- data.frame(keyName = names(
  lsa.pros$features[, 16]),
  value = lsa.pros$features[, 16],
  row.names = NULL
)

topic16 %>% arrange(value)
```

