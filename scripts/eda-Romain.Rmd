---
title: "EDA-Romain"
output: html_document
---

```{r setup, include=FALSE,message=FALSE}
source(here::here("scripts/setup.R"))
```

# Exploratory Data Analysis

## Complete pros reviews set (each review is a doc)
```{r }
#importation of the corpus
reviews.complete <- read_csv(here::here("data/Bank_reviews_processed.csv"))

#corpus for the pros
reviews.corpus.pro <- corpus(x = reviews.complete,
                             text_field = c("employer_pros"))

```

### Tokenization
```{r }
### tokenization
library(lavaan)

#Romain: no need for word1 argument, as we are not concerned by symbols or whatever.
reviews.tokens.pro <- tokens(reviews.corpus.pro, 
                        remove_punct = TRUE, 
                        remove_symbols = TRUE, 
                        what="word")

#Use of stemming / could also use lemmitization
reviews.tokens.pro <- tokens_tolower(reviews.tokens.pro) %>% 
  tokens_wordstem() %>%
  tokens_remove(stopwords("english"))
```



## PROS sorted by bank
```{r}
reviews.company <-reviews.complete$company
reviews.pro.dfm$company <-reviews.company
reviews.bank.pro.dfm<-dfm_group(reviews.pro.dfm,groups = "company")

#frequency per terms
reviews.bank.pro.freq <- textstat_frequency(reviews.bank.pro.dfm,groups = "company")

#tf_idf
reviews.bank.pro.dfm.tfidf<-dfm_tfidf(reviews.bank.pro.dfm)

index <- reviews.bank.pro.freq %>% top_n(15)
index <- index %>% filter(rank<15)
reviews.bank.pro.freq %>% 
  filter(feature %in% index$feature) %>% 
  ggplot(aes(feature, frequency)) + 
  geom_col() + 
  coord_flip() +
  facet_wrap(~group, ncol = 3) +
  labs(title="Whole dataset top 15 token frequency by bank")
```
Interistingly, it seems that great is more frequent than good for english-speaking banks. This is maybe the consequence of native english speaker vs non-native english speaker. To be checked with


### Keyness analysis for each bank compared to the other
```{r}
company <- docnames(reviews.bank.pro.dfm)
res <- numeric(length = length(company))

for (i in 1:length(company)) {
  text2.kn <- textstat_keyness(reviews.bank.pro.dfm, target = i)
  print(textplot_keyness(text2.kn))
}
```


### Compare the reviews in terms of lexical diversity
```{r}
textstat_lexdiv(reviews.bank.pro.dfm,
                measure = "I") %>%
  ggplot(aes(x = reorder(document, I), y = I)) +
  geom_point() +
  coord_flip() +
  xlab("Text") +
  ylab("Yule's index")
```

### Job analysis
Here my goal is to see if jobs positions are really different from one company to another
```{r}
# select and clean variable employee_role
reviews.complete <-
  separate(
    data = reviews.complete,
    col = employee_role,
    into = c(NA, "employee_role"),
    sep = "\\-"
  )

jobs.corpus <- corpus(x = reviews.complete,
                      text_field = c("employee_role"))

jobs.tokens <- tokens(
  jobs.corpus,
  remove_punct = TRUE,
  remove_symbols = TRUE,
  what = "sentence"
)

jobs.dfm <- dfm(jobs.tokens) # create dfm
jobs.dfm$company <- reviews.complete$company
jobs.dfm <- dfm_group(jobs.dfm, groups = "company") %>% 
  dfm_sort(decreasing=TRUE)
jobs.dfm <- jobs.dfm[,1:100] #sort dfm by only keeping most used term

#filter unapropriate terms
junk <- c(" anonymous employee",
          " teller ii",
          " teller i" ,
          " vice president",
          " assistant vice president",
          " director",
          " associate director"
          )
jobs.dfm <- jobs.dfm %>% dfm_remove(junk)

# display position frequency by bank
reviews.bank.pro.freq <- textstat_frequency(reviews.bank.pro.dfm,groups = "company")
textstat_frequency(jobs.dfm,groups = "company") %>%
  arrange(desc(frequency)) %>%
  filter(rank<15) %>% 
  ggplot(aes(x=feature, y=frequency)) + 
  geom_col() + 
  coord_flip()

# Representation of the job position on the biplot
tmod <- textmodel_lsa(jobs.dfm, nd = 3)

biplot(
  y = tmod$docs[, 2:3],
  x = tmod$features[, 2:3],
  col = c("grey", "red"),
  xlab = "Dim 2",
  ylab = "Dim 3",
  cex=0.8
)

```

# Sentiment analysis using valence-shifters for the pros reviews
Trying to understand if positive reviews employee sentiments vary from bank to bank.
Obviously, some reviews are really short and do not contain any sentiment. However, I suppose that some reviews are more develloped and could potentially contain sentiment/feeling that could be interesting.

```{r}
#need to create one vector/bank which contain all the review
company<- unique(reviews.complete$company)
review.storage <- character(5)

for (i in 1:length(company)) {
review.storage[i,]<-reviews.complete %>%
  filter(company== i) %>%
  select(employer_pros) %>%
  str_c(sep = "",collapse = TRUE)
}


reviews.complete %>%
  filter(company== "TD") %>%
  select(employer_pros) %>%
  str_c(sep = " ",collapse = TRUE)

company
```






