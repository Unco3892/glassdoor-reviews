---
title: "EDA"
output: html_document
---

```{r setup, include=FALSE}
# Loading packages and knitr options
source(here::here("scripts/setup.R"))

# Importing the data
bank_reviews <- read_csv(here::here("data/Bank_reviews_processed.csv"))

```

## Preprocessing

### Definitions

`Corpus` = All reviews on GlassDoor for five major banks

`Text` = Reviews for each bank --> Used this also as the `Document`

`Tokens` = Words in each review

### Data structure

```{r}
bank_reviews %>% kable_head()
```

<br />
The dataset consists of `r length(unique(bank_reviews$company))` banks which are `r unique(bank_reviews$company) %>% paste(.,collapse = ", ")`. We also remark that employer rating is always filled, but this is not true for the other ratings, such as work life balance, that employee choose or not to answer.
<br />

### Checking for NAs and duplicates.

```{r,echo=FALSE}
freq.na(bank_reviews) %>% kable_maker(caption="Overview of the missing values",
                                      col.names=c("Number of missing values","%")) 
```

<br />
As mentionned above, not all ratings are mandatory to be filled, for example the diversity inclusion is mostly not considered. This indicates that we wont be able to use all of these variables for further classifiation tasks.
<br />

```{r, echo=FALSE, results='hide'}
#sum(duplicated(bank_reviews$review_id)) #The output shows that 429 reviews are duplicated, let's check them

# All the row's who values are duplicated
bank_reviews %>%
filter(duplicated(review_id))

# These are all the duplicated values
bank_reviews %>% group_by(review_id) %>% filter(n()>1) %>% ungroup() %>% kable_head()

# We look at a specific example
#bank_reviews %>% filter(review_id == "empReview_38099527")

# We will remove these rows
bank_reviews %<>%
  filter(!duplicated(review_id))

# We confirm that the duplicates are no longer there
#bank_reviews %>% filter(review_id == "empReview_38099527")
```

<br />
For unknown reasons, some reviews seem to have been duplicated, approximatively 429. We remove these instances from our dataset to ensure its good quality. 
<br />

### General overview
```{r, warning=FALSE, message=FALSE}
bank_reviews %>%
  select(company, employer_rating:senior_management) %>%
  group_by(company) %>%
  add_count() %>%
  summarize_if(is.numeric,
               c(
                 "mean" = function(x)
                   mean(x, na.rm = TRUE)
                 # "median" = function(x)
                 #   median(x, na.rm = TRUE)
               )) %>%
  # relocate(company, n_median) %>%
  # rename("number of reviews" = n_median) %>%
  kable_maker(col.names=c("Bank name",
                          "Number of reviews",
                          "Rating",
                          "Work life balance",
                          "Culture values",
                          "Diversity inclusion",
                          "Career Opportunities",
                          "Compensations and benefits",
                          "Senior management"),caption="Overview of average scores")
```


```{r, warning=FALSE, message=FALSE}
# calculating the mean number of words
# mean_words_cal <- function(a_word_column) {
#   mean(sapply(strsplit(
#     as.character(a_word_column), "[[:space:]]"
#   ), length))
# }

mean_words_cal <- function(a_word_column) {
  mean(sapply(str_count(as.character(a_word_column), '\\w+'), sum))
}

# median_words_cal <- function(a_word_column) {
#   median(sapply(strsplit(
#     as.character(a_word_column), "[[:space:]]"
#   ), length))
# }

median_words_cal <- function(a_word_column) {
  median(sapply(str_count(as.character(a_word_column), '\\w+'), sum))
}



quantile_fun <- function(a_word_column,a_quantile) {
  quantile(sapply(str_count(as.character(a_word_column), '\\w+'), sum), a_quantile, na.rm = TRUE)
}

# applying the function to the two word columns
bank_reviews %>% group_by(company) %>%
  summarize(across(
    c(employer_pros, employer_cons),
    c(
      "1st_Qu." = function(x)quantile_fun(x, 0.25),
      "Median" = median_words_cal,
      "Mean" = mean_words_cal,
      "3rd_Qu." = function(x) quantile_fun(x, 0.75)
    )
  )) %>%
  gather(metric, val, 2:ncol(.)) %>%
  spread(company, val) %>% 
  kable_maker(caption="Pros and cons review word length: comparison between banks")

```

<br />
Regarding the number of words per bank for the reviews, we cannot identify interesting patterns. If we look at the median and the mean number of words for cons reviews, we do not find similar results compared to the scores. It would have been interesting to see that longer cons reviews are correlated with bad score, as angry employees would emphasize the negative points of the company instead of the positive, but this is not the case here.
<br />

```{r fig3, fig.width = 6, fig.asp = .72,out.width = "75%"}

count_words_cal <- function(a_word_column) {
  sapply(str_count(as.character(a_word_column), '\\w+'), sum)
}

e<-bank_reviews %>%
  mutate(word=count_words_cal(employer_pros)) %>%
  group_by(word) %>%
  summarise(n=n()) %>%
  filter(word<50) %>%
  ggplot(aes(x=word,y=n)) +
  geom_col() +
  ylab("Number of reviews") +
  xlab("Number of words") +
  labs(title="Pros")

f<-bank_reviews %>%
  mutate(word=count_words_cal(employer_cons)) %>%
  group_by(word) %>%
  summarise(n=n()) %>%
  filter(word<50) %>%
  ggplot(aes(x=word,y=n)) +
  geom_col() +
  ylab("") +
  xlab("Number of words") +
  labs(title="Cons")

ggarrange(e,f,
          ncol=2,nrow=1)

```

<br />
Both graphs above clearly show that the number of word per review is quite concentrated around 5-6 words. This result is not surprising, as every new Glassdoor member need to write minimum length pro and con reviews for account validation. Most of them write a very short review.
<br />


## General explorations
A general EDA for the reviews. Note that here we treat each company as a document. Our dataset is then composed of 23341 documents.


### Tokenization
Text Mining results are largely impacted by the tokenization process. After testing differents options, we decide to use the lemmatization as it is the most promising option. 

We create the function EDA_handler, that deals with every aspect of the tokenization. The tokens are split by word and we also remove the stopwords. We also do not want to take into consideration the case and lowercase the tokens.

```{r,message=FALSE,echo=TRUE}
# creating function to take out the pros and cons of the reviews
EDA_handler <-
  function (a_tibble,
            text_column,
            n_top = 20,
            TF_grouped = FALSE,
            TF_IDF = FALSE,
            word_cloud = FALSE,
            aggregate_cloud = FALSE,
            lemma=FALSE) {
    # creating the new column name
    new_col <- paste0(quo_name(enquo(text_column)), "_word")
    # tokenization of the reviews
    review_token <- tidytext::unnest_tokens(
      a_tibble,
      output = "word",
      input = {{text_column}},
      to_lower = TRUE,
      strip_punct = TRUE,
      strip_numeric = TRUE) %>%
      # if the lemmatization option is activated
      `if`(lemma,{.} %>% mutate(word = lemmatize_strings(word)),.) %>%
      # removing the stop words
      anti_join(., stop_words, by = "word") %>%
      rename(., !!(new_col) := "word")
    # looking at the most frequent words
    freq <- review_token %>%
      group_by(company) %>%   # grouping is also possible also with review_id
      count("{{text_column}}_word" := get(new_col), sort = TRUE) %>%
      ungroup()
    # computing the TF-IDF if the option is set as TRUE
    if (TF_IDF == TRUE) {
      reviews_TF_IDF <- tidytext::bind_tf_idf(
        tbl = freq,
        term = !!(new_col),
        document = company,
        n = n
      )
    }
    # indexing for the top n words and also if it was a TFI-IDF then use that
    # for the index instead of the the typical frequency table
    index <-
      `if`(TF_IDF, reviews_TF_IDF, freq) %>%
      `if`(TF_grouped, {.} %>% group_by(company), .) %>%
      top_n(n_top)
    # creating a function to be used for the ggplot aesthetics
    fix_lables <- function (a_column) {
      stri_replace_all_fixed(a_column, c("_", "s"), c(" ", ""), vectorize_all = FALSE)
    }
    # designing a ggplot for the most frequent words
    freq_plt <-
      `if`(TF_IDF, reviews_TF_IDF, freq) %>%
      filter(get(new_col) %in% (index %>% pull(get(new_col)))) %>%
      ggplot(aes(x = get(new_col), y = `if`(TF_IDF, tf_idf, n), fill= get(new_col))) + 
      geom_col() + 
      coord_flip() + 
      facet_grid( ~ company) + 
      theme_light() +
      # another alternative for the wrap --> facet_wrap(~company, ncol = 2)
      labs(
        title = paste0("Most frequent ",
                       fix_lables(new_col),
                       "s per bank"),
        y = `if`(TF_IDF, "TF_IDF", NULL),
        x = fix_lables(new_col)
      )
    
    # creating wordcloud if the option is set equal to TRUE
    if (word_cloud == TRUE) {
      set.seed(1234)
      # dev.new(width = 1000, height = 1000, unit = "px")
      #many warnings are generated on this which is normal
      if (aggregate_cloud == TRUE) {
        freq_agg <- aggregate(as.formula(paste("n", "~", new_col, sep= " "))
                              , FUN = sum, data=freq)
      }
      clouds <-
        wordcloud::wordcloud(
          words = (`if`(aggregate_cloud,freq_agg, freq) %>% pull(!!new_col)),
          freq = (`if`(aggregate_cloud,freq_agg, freq) %>% pull(n)),
          min.freq = 2,
          max.words = 10,
          random.order = FALSE,
          random.color = FALSE,
          colors = brewer.pal(8, "Dark2"))
    }
    
    # generating the output
    output <-
      list(
        review_token,
        # "Remove_stopwords" = review_token,
        "Most_frequent_words" = freq,
        # if(exists("clouds")){"Word_cloud" = clouds},
        "Plotting_most_frequent_words" = freq_plt
      )
    
    # we also add the wordcloud if available
    if(word_cloud==TRUE){
      clouds <- list("Word_cloud"=clouds)
      output <- append(output,clouds)
      }
    
    # changing the name of the object based on the option given
    names(output)[1] <-
      `if`(lemma,"Remove_stopwords_make_lemma","Remove_stopwords")

    return(output)
  }
```


```{r, echo=FALSE,message=FALSE}
EDA_handler(bank_reviews, employer_pros, n_top = 1, word_cloud = T, aggregate_cloud = TRUE, lemma=TRUE)

# TF approach
pros_tf <- EDA_handler(bank_reviews, employer_pros, lemma=TRUE)
cons_tf <- EDA_handler(bank_reviews, employer_cons, lemma=TRUE)


# TF_IDF approach
pros_tf_idf <- EDA_handler(bank_reviews, employer_pros, n_top = 5,TF_grouped= TRUE, TF_IDF = TRUE)
cons_tf_idf <- EDA_handler(bank_reviews, employer_cons, n_top = 1,TF_grouped= TRUE, TF_IDF = TRUE)

# The grouped and specific to each document --> Only one word is shown which is quite strange and requires more investigation
pros_grouped <- EDA_handler(bank_reviews, employer_pros, n_top = 1, TF_grouped= TRUE)

# generating word cloud, note that you always get `null` in the output which
# is because based on base graphics and the side effect of drawing to the current graphics device.
pros_cloudy <- EDA_handler(bank_reviews, employer_pros, n_top = 1, word_cloud = TRUE)

# generating aggregated wordcloud
pros_cloudy_aggregated <- EDA_handler(bank_reviews, employer_pros, n_top = 1, word_cloud = T, aggregate_cloud = TRUE, lemma=TRUE)

cons_cloudy_aggregated <- EDA_handler(bank_reviews, employer_cons, n_top = 1, word_cloud = T, aggregate_cloud = TRUE, lemma=TRUE)

# note: in the rmarkdown approach you may have a warning that management could not fit on the screen, this is normal and in case it occurred a picture has to be posted of this.
```

The ggplot represents the most frequent words per company as the grouping was not done on the review but the company itself.

Regarding the pros, most often the words `benefit` and `people` come up, it is also interesting to see that the words `culture`, and `life` are also there perhaps indicating that most people care about these values when trying to describe work positively.

We can see that the most cons were associated with the word `management`. This is followed by `employees`, `hour` and `time`. Furthermore we have the same `people` word in the cons meaning that we would have to put our analysis into context and use the valence sifters to see if they mention something good about people or bad about these people.

Also `quanteda` library could be used if needed..

```{r}
pros_corpus <- bank_reviews %>% select(company, review_id, employer_pros) %>% corpus(text_field = "employer_pros")
```

### Semantic Analysis
Sentiment analysis with the two dictionaries of `nrc` and `afinn`.

```{r,message=FALSE}
# Dictionaries for categories
get_sentiments("nrc")

# Dictionaries by values
get_sentiments("afinn")

# Use the lemmatized words and join them with a dictionary of choice
dicti_senti <-
  function (a_tf_object,
            a_dictionary,
            a_plot = FALSE) {
    # Using the tf matrix and removing the stop words
    tf_no_stop <- {
      a_tf_object
    }[[1]] %>%
      rename(word = contains("word")) #pro or con word
    
    # nrc option
    if (a_dictionary == "nrc") {
      nrc_sentiment <-
        tf_no_stop %>% inner_join(get_sentiments("nrc"))
      if (a_plot == TRUE) {
        plt <-
          nrc_sentiment %>%
          group_by(company, sentiment) %>%
          summarize(n = n()) %>%
          mutate(freq = n / sum(n)) %>%
          ggplot(aes(x = sentiment, y = freq, fill = sentiment)) +
          geom_bar(stat = "identity", alpha = 0.8) +
          facet_wrap(~ company) +
          coord_flip() +
          xlab("") +
          labs(title="PRO/CON: Sentiment analysis using nrc dictionnary")
      }
      # in case a plot was requested we return it otherwise we just return the
      # sentiment output
      out<-
        tryCatch(
        expr = {
          output_nrc <-
            list("nrc_sentiments" = nrc_sentiment, "plot_of_nrc" = plt)
          return(output_nrc)
        },
        error = function(e) {
          return(nrc_sentiment)
        }
      )
      return(out) #if this is not done, then it'll return a null 
      # when a plot is not used
    }
    # afinn option
    if (a_dictionary == "afinn") {
      afinn_sentiment <-
        tf_no_stop %>% inner_join(get_sentiments("afinn"))
      if (a_plot == TRUE) {
        aggregated_measure <-
          aggregate(value ~ company, data = afinn_sentiment, FUN = mean)
        plt <-
          aggregated_measure %>% 
          ggplot(aes(x = company, y = value, fill = company)) +
          geom_bar(stat = "identity") +
          coord_flip() +
          ylab("freq") +
          xlab("") +
          labs(title="PRO/CON: Sentiment analysis using Afinn dictionnary",fill="Bank name")
          
      }
      
      # applying the same logic as before
      tryCatch(
        expr = {
          output_afinn <-
            list("afinn_sentiments" = afinn_sentiment,
                 "plot_of_afinn" = plt,
                 "aggregated_measure"=aggregated_measure)
          return(output_afinn)
        },
        error = function(e) {
          return(afinn_sentiment)
        }
      )
    }
  }


# looking at nrc pros and cons separately
pos_nrc_sem <- dicti_senti(pros_tf, a_dictionary = "nrc", a_plot=TRUE)
neg_nrc_sem <- dicti_senti(cons_tf, a_dictionary = "nrc", a_plot=TRUE)

# we can also combine the two reviews and look at them in that way
make_wider <- function(a_tibble) {
  a_tibble$Remove_stopwords_make_lemma %>% pivot_longer(
    cols = contains("word"),
    names_to = "type_of_review",
    names_pattern = "employer_(\\D+)s",
    values_to = "word"
  )
}

nrc_combined <- bind_rows(make_wider(pros_tf), make_wider(cons_tf))

# applying it to the combined set of reviews
a<-dicti_senti(list(nrc_combined), a_dictionary = "nrc", a_plot=TRUE)
b<-dicti_senti(list(nrc_combined), a_dictionary = "afinn", a_plot=TRUE)


# doing the same with the afinn dictionary 
pos_afinn_sem <- dicti_senti(pros_tf, a_dictionary = "afinn", a_plot=TRUE)
neg_afinn_sem <- dicti_senti(cons_tf, a_dictionary = "afinn", a_plot=TRUE)

# computing the total for afiin, we add positives to negative semantics. 
scores_compared <- pos_afinn_sem$aggregated_measure %>% 
  left_join(neg_afinn_sem$aggregated_measure, by = "company") %>% 
  mutate(afinn_senti_score = value.x+value.y) %>% 
  arrange(desc(afinn_senti_score)) %>%
  select(-c(2,3))

a$plot_of_nrc
```

<br />
The feelings for the banks are very close to one another for the `nrc` method. Unfortunately, we won't be able to use nrc dictionnary for classification.
<br />

```{r}
b$plot_of_afinn
```

<br />
Using Afinn dictionnary, the sentiment analysis seems more promising. It really emphasize the importance of choosing the correct dictionary. The Afinn contains over 3,300+ words with a polarity score associated with each word. 
<br />

### More advanced methods with valence shifters.

```{r}
# Here we add the scores of the reviews which is more custom to our purpose
val_shifter <- function (a_tibble){
  object_1 <- a_tibble %>%
    dplyr::mutate(pros = get_sentences(employer_pros)) %$%
    sentiment_by(pros, list(company, review_id))
  
  object_2<- a_tibble %>%
    dplyr::mutate(cons = get_sentences(employer_cons)) %$%
    sentiment_by(cons, list(company, review_id))
  
  overall_score <-object_1 %>% 
    left_join(object_2, by = c("company", "review_id")) %>%
    mutate(score_numerical_analysis = ave_sentiment.x + ave_sentiment.y) %>%
    select(1, 2, score_numerical_analysis)
  
  average_score <- overall_score %>% group_by(company) %>%
    summarize(valshifter_senti_score=mean(score_numerical_analysis))
  
  return(average_score)
  }

# Applying the function to the bank reviews
valence_score<-val_shifter(bank_reviews)

# calculating the actual score they have given to each company
actual_score <- 
  aggregate(employer_rating~company, data=bank_reviews, FUN=mean) %>% 
  arrange(desc(employer_rating))

# Comparing the score of valence shifter vs the basic numerical sentiment
actual_score %>% 
  left_join(valence_score,by = "company") %>% 
  left_join(scores_compared,by = "company") %>%
  rename(actual_employer_rating = employer_rating) %>% 
  arrange(desc(2)) %>% kable_maker(caption="Employer rating: Comparison with 2 sentiment analysis methods",
                                      col.names=c("Bank name",
                                                  "Actual employer rating",
                                                  "Valence shifter score",
                                                  "Afinn sentiment score"))
```

We get a score that 4/5 times the sentiment corresponds to the actual score. More importantly, it highlights the differences in the scores with Morgan Stanley drastically being in lead. Consequently, this new approach of valence shifter score is a good candidate for classification. We choose to integrate it for the supervised learning part.

### Job positions analysis

In order to have the most accurate classifier, we need to have a look at every variable available. During the scraping process, we have also managed to extract the job position. It makes sense to have a look at it to see if the employee role has an impact on the company review score.

```{r fig4, out.width = "90%"}

# We select and clean variable employee_role
clean.bank.review <-
  separate(
    data = bank_reviews,
    col = employee_role,
    into = c(NA, "employee_role"),
    sep = "\\-"
  )

jobs.corpus <- corpus(x = clean.bank.review ,
                      text_field = c("employee_role"))

jobs.tokens <- quanteda::tokens(
  jobs.corpus,
  remove_punct = TRUE,
  remove_symbols = TRUE,
  what = "sentence"
)

jobs.dfm <- dfm(jobs.tokens) # create dfm
jobs.dfm$company <- bank_reviews$company
jobs.dfm <- dfm_group(jobs.dfm, groups = "company") %>% 
  dfm_sort(decreasing=TRUE)

# We filter the unapropriate terms
to.be.removed <- c(" anonymous employee",
          " teller ii",
          " teller i" ,
          " vice president",
          " assistant vice president",
          " director",
          " associate director"
          )
jobs.dfm <- jobs.dfm %>% dfm_remove(to.be.removed)
jobs.dfm <- jobs.dfm[,1:50] #sort dfm by only keeping most used term for better display

# We display position frequency by bank

jobs.freq <- textstat_frequency(jobs.dfm,groups = "company")
index.jobs <- jobs.freq 

jobs.freq %>%
  arrange(desc(frequency)) %>%
  filter(rank<=5) %>%
  ggplot(aes(x=feature, y=frequency)) + 
  geom_col() + 
  coord_flip() +
  facet_wrap(~group, ncol = 3) +
  labs(title="Top 5 most frequent position for each bank") + xlab("") +ylab("")


```
We have also explored the job positions to potentially identify patterns. After removing unaccurate job-title, we observe on the top 5 most frequent position per bank that some position seems more specific for one's bank. For instance, UBS seems to hire a larger number of interns for its operations.

```{r fig5, out.width = "70%",fig.asp=1.1}

# Representation of the job position on the biplot
tmod <- textmodel_lsa(jobs.dfm, nd = 3)

biplot(
  y = tmod$docs[, 2:3],
  x = tmod$features[, 2:3],
  col = c("grey", "red"),
  xlab = "Dim 2",
  ylab = "Dim 3",
  cex=0.8
)
```


To have a more interpretable insight and using LSA techniques, we manage to biplot in 2 dimensions the top 50 job positions. Interestingly, JP Morgan, HSBC and UBS seem to have a similar job structure. On the other, TD offers more position related to representant (customer oriented), whereas DB hire more analysts.

### Compare the reviews in terms of lexical diversity

Lexical diversity can also be an interesting tool for classification. However, it seems unlikely to have a usable result here. The only expanation would be that maybe some specific banks hire many more non-english native, who english richness is lower.


```{r fig6,fig.width=9,out.width = "90%"}

#corpus for the pros
reviews.corpus.pro <- corpus(x = bank_reviews,
                             text_field = c("employer_pros"))

### tokenization
library(lavaan)

#Romain: no need for word1 argument, as we are not concerned by symbols or whatever.
reviews.tokens.pro <- quanteda::tokens(reviews.corpus.pro, 
                        remove_punct = TRUE, 
                        remove_symbols = TRUE, 
                        what="word")

# We decide to remove words that won't bring additional information, such as the name of the bank, etc.
to.be.removed <- c("ubs","jp","chase","td","morgan","hsbc","deutsche","db","jpmc","j.p","jpmorgan")

#Use of lemmitization
reviews.tokens.pro <- tokens_tolower(reviews.tokens.pro) %>% tokens_replace(pattern=hash_lemmas$token, replacement = hash_lemmas$lemma) %>% tokens_remove(c(stopwords("english"),to.be.removed))

reviews.pro.dfm <- dfm(reviews.tokens.pro)
reviews.company <-bank_reviews$company
reviews.pro.dfm$company <-reviews.company
reviews.bank.pro.dfm<-dfm_group(reviews.pro.dfm,groups = "company")

#frequency per terms
reviews.bank.pro.freq <- textstat_frequency(reviews.bank.pro.dfm,groups = "company")

#tf_idf
reviews.bank.pro.dfm.tfidf<-dfm_tfidf(reviews.bank.pro.dfm)

a<-textstat_lexdiv(reviews.bank.pro.dfm,
                measure = "I") %>%
  ggplot(aes(x = reorder(document, I), y = I)) +
  geom_point() +
  coord_flip() +
  xlab("") +
  ylab("Yule's index")

b<-textstat_lexdiv(reviews.bank.pro.dfm,
                measure = "TTR") %>%
  ggplot(aes(x = reorder(document, TTR), y = TTR)) +
  geom_point() +
  coord_flip() +
  xlab("") +
  ylab("TTR's index")

ggarrange(a,b,
          ncol=2,nrow=1)
# textstat_lexdiv(reviews.bank.pro.dfm,
#                 measure = "MATTR") %>%
#   ggplot(aes(x = reorder(document, MATTR), y = MATTR)) +
#   geom_point() +
#   coord_flip() +
#   xlab("Text") +
#   ylab("MATTR's index")
```

We use both Yule's index and TTR's index to demonstrate that they are not candidate for classification. Both graphs tell very diffferents stories, and we cannot correlate these results with the employee_review.

