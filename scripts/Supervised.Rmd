---
title: "Embedding-JDL"
output: html_document
---


```{r , include=FALSE}
# Loading packages and knitr options
source(here::here("scripts/setup.R"))

library(lexicon)
library(ngram)
library(ranger)
```

```{r,echo=FALSE}
#The output shows that 429 reviews are duplicated
# We will remove these rows
bank_reviews %<>%
  filter(!duplicated(review_id))
```

```{r, include=FALSE}
# Importing the data
bank_reviews <-
  read_csv(here::here("data/Bank_reviews_processed.csv"))

# Apply a filter to remove the duplicated entries and also add sentiments separately for pros and con which we will combine later. The word count was also added
bank_reviews %<>%
  filter(!duplicated(review_id)) %>%
  dplyr::mutate(
    pro_sen_score = sentimentr::sentiment_by(text.var = get_sentences(employer_pros))$ave_sentiment,
    # we did not use the sentiment function as it gave some recycling issues. We use get_sentences to avoid warnings but it is not necessary
    cons_sen_score = sentimentr::sentiment_by(get_sentences(employer_cons))$ave_sentiment,
    pros_w_count = str_count(employer_pros, '\\w+'),
    cons_w_count = str_count(employer_cons, '\\w+')
  )

# Corpus creation for pros
corpus.pros <- corpus(x = bank_reviews,
                      text_field = c("employer_pros"))

# Corpus creation for pros
corpus.cons <- corpus(x = bank_reviews,
                      text_field = c("employer_cons"))
```

```{r}
# tokens for pros
tokenize_reviews <- function(a_corpus) {
  tokens.pros <- quanteda::tokens(
    a_corpus,
    remove_punct = TRUE,
    remove_symbols = TRUE,
    remove_url = TRUE
  ) %>%
    tokens_tolower() %>%
    tokens_remove(
      c(
        "bank",
        "ubs",
        "jpmorgan",
        "hsbc",
        "td",
        "deutsche" ,
        "#name",
        "good",
        "great",
        stopwords("english")
      )
    ) %>%
    tokens_replace(pattern = hash_lemmas$token, replacement = hash_lemmas$lemma)
}

# tokens for pros
tokens.pros <- tokenize_reviews(corpus.pros)

# tokens for cons
tokens.cons <- tokenize_reviews(corpus.cons)
```


```{r}
# Keeping reviews with more than a certain number of token for pros & cons
min.token <- 10

tokens.pros.clean <- tokens.pros %>%
  tokens_subset(ntoken(tokens.pros) > min.token & ntoken(tokens.cons) > min.token)

tokens.cons.clean <- tokens.cons %>%
  tokens_subset(ntoken(tokens.cons) > min.token & ntoken(tokens.pros) > min.token)
```


```{r}
# dfm pros
dfm.pros <- dfm(tokens.pros.clean)

# dfm cos
dfm.cons <- dfm(tokens.cons.clean)

# tfidf pros
tfidf.pros <- dfm_tfidf(dfm.pros)

# tfidf cons
tfidf.cons <- dfm_tfidf(dfm.cons)
```


```{r}
# Retrieving the ratings
y <- docvars(tokens.pros.clean, "employer_rating")

# Creating the training Set
set.seed(123)
index.tr <- sample(size=round(0.8*length(y)), x=c(1:length(y)), replace=FALSE)
```

# DTM
```{r}
# Creating a result Dataframe
results_lsa_dtm <- expand.grid(
  "method" = c("LSA"),
  "input" = c("DTM"),
  "dimPos" = c(5, 20, 30, 50),
  "dimCons" = c(5, 20, 30, 50),
  "LM" = NA,
  "RF" = NA,
  # NA columns for our future calculations
  stringsAsFactors = FALSE
) %>%
  arrange(dimPos, dimCons)


# Compute the RMSE for each combination of #Topic for pros and cons
for (i in 1:nrow(results_lsa_dtm)){
  #LSA
  lsa.pros <- textmodel_lsa(dfm.pros, nd=results_lsa_dtm$dimPos[i])
  lsa.cons <- textmodel_lsa(dfm.cons, nd=results_lsa_dtm$dimCons[i])
  # df <- data.frame(Score=y, X1=lsa.pros$docs, X2=lsa.cons$docs)
  
  df <- data.frame(
    Score = y,
    topic.pros = lsa.pros$docs,
    topic.cons = lsa.cons$docs,
    total_sen_score = rowSums(docvars(tokens.pros.clean, c("pro_sen_score", "cons_sen_score")))
  )

    
  df.tr <- df[index.tr,]
  df.te <- df[-index.tr,]
  
  set.seed(100)
  #LM
  reviews.lm <- lm(Score ~ .,
                   data = df.tr)
  pred.lm <- predict(reviews.lm, df.te)
  pred.lm <- pmin(5, predict(reviews.lm, df.te))
  results_lsa_dtm$LM[i] <- sqrt(mean((pred.lm - df.te$Score) ^ 2)) 
  
  #RF
  reviews.rf <- ranger(Score ~ .,
                       data = df.tr)
  pred.rf <- predict(reviews.rf, df.te)$predictions
  results_lsa_dtm$RF[i] <- sqrt(mean((pred.rf - df.te$Score) ^ 2))
  }
```


# TFIDF

```{r}
results_lsa_tfidf <- expand.grid(
  "method" = c("LSA"),
  "input" = c("TFIDF"),
  "dimPos" = c(5, 20, 30, 50),
  "dimCons" = c(5, 20, 30, 50),
  "LM" = NA,
  "RF" = NA,
  # NA columns for our future calculations
  stringsAsFactors = FALSE
) %>%
  arrange(dimPos, dimCons)

# Compute the RMSE for each combination of #Topic for pros and cons
for (i in 1:nrow(results_lsa_tfidf)){
  #LSA
  lsa.pros <- textmodel_lsa(tfidf.pros, nd=results_lsa_tfidf$dimPos[i])
  lsa.cons <- textmodel_lsa(tfidf.cons, nd=results_lsa_tfidf$dimCons[i])
  # df <- data.frame(Score=y, X1=lsa.pros$docs, X2=lsa.cons$docs)
  
  df <- data.frame(
  Score = y,
  topic.pros = lsa.pros$docs,
  topic.cons = lsa.cons$docs,
  total_sen_score = rowSums(docvars(
    tokens.pros.clean, c("pro_sen_score", "cons_sen_score")))
    # total_word_count = rowMeans(docvars(
    #     tokens.pros.clean, c("pros_w_count", "cons_w_count")
  )
  
  df.tr <- df[index.tr,]
  df.te <- df[-index.tr,]
  
  set.seed(100)
  #LM
  reviews.lm <- lm(Score ~ .,
                   data = df.tr)
  pred.lm <- predict(reviews.lm, df.te)
  pred.lm <- pmin(5, predict(reviews.lm, df.te))
  results_lsa_tfidf$LM[i] <- sqrt(mean((pred.lm - df.te$Score) ^ 2))

  #RF
  reviews.rf <- ranger(Score ~ .,
                       data = df.tr)
  pred.rf <- predict(reviews.rf, df.te)$predictions
  results_lsa_tfidf$RF[i] <- sqrt(mean((pred.rf - df.te$Score) ^ 2))
  }
```


```{r}
# combining the results
results_lsa <- rbind(results_lsa_dtm, results_lsa_tfidf)

results_lsa <- results_lsa %>%
  gather(LM, RF, key = "learner", value = "RMSE")


bestmodel <- results_lsa %>%
  top_n(-1, RMSE)

# best models : 
results_lsa %>%
  top_n(-15, RMSE) %>%
  arrange(RMSE)

# worst models : 
results_lsa %>%
  top_n(10, RMSE) %>%
  arrange(desc(RMSE))
```


Could add the valence shifters to the combination as well as the log count for the cons.

JDL : Woudln't add the word count since it is already reflected in topic 1 for pros & cons.

# Best model (TF-IDF + LSA)
We can also the valence shifter and the long length of the reviews to it.

```{r}
lsa.pros <- textmodel_lsa(tfidf.pros, nd = bestmodel$dimPos)
# lsa.cons <- textmodel_lsa(tfidf.cons, nd = 20)
# Even better for the cons to be 30
lsa.cons <- textmodel_lsa(tfidf.cons, nd =  bestmodel$dimCons)
df <- data.frame(
  Score = y,
  pros = lsa.pros$docs,
  cons = lsa.cons$docs,
  # Note that in the code below, we can use either tokens.pros.clean or tokens.cons.clean as they both contain the same sentiment and word count columns
  total_sen_score = rowSums(docvars(
    tokens.pros.clean, c("pro_sen_score", "cons_sen_score")
  ))
)

df.tr <- df[index.tr, ]
df.te <- df[-index.tr, ]

#RF
set.seed(100)
reviews.rf <- ranger(Score ~ .,
                     data = df.tr,
                     importance = "impurity")
pred.rf <- predict(reviews.rf, df.te)$predictions

# rmse <- sqrt(mean((pred.rf - df.te$Score)^2))
# rmse
# 0.991 however it does not look as good as the LSA one
```


```{r}
plot(pred.rf ~ df.te$Score, ylab="Predictions", xlab="Observed", pch=20)
```
What worked well and what didn't:
- Without the log for both combined looks better it looks better
- Taking the log10 of just pros_w_count is slightly better than the other models but not much and does not make much sense.
- Taking the mean of the rows instead of the sum did not work either
- Having only the sentiments is enough, also don't forget to set seed

# Variable importance

```{r}
imp <- data.frame(keyName=names(reviews.rf$variable.importance), value=reviews.rf$variable.importance, row.names=NULL)

imp$type[1:51] <- "pros"
imp$type[21:51] <- "cons"
imp$type[51:51] <- "other"
```

```{r}
imp %>%
  mutate(name = fct_reorder(keyName, value)) %>%
  ggplot(aes(x = name, y = value, fill = type)) +
  geom_bar(stat = "identity",
           alpha = .6,
           width = .4) +
  coord_flip() +
  xlab("") +
  ylab("impurity") +
  theme_bw() +
  scale_fill_manual(breaks = c("pros", "cons", "other"),
                       values=c("green", "red", "blue"))
```

- Lenght of cons important,
- Lenght of pos too,
- sentiment score helps predicting greatly
- cons 3 seems to be an important topic

```{r}
cons.3 <- data.frame(keyName = names(
  lsa.cons$features[, 3]),
  value = lsa.cons$features[, 3],
  row.names = NULL
)

cons.3 %>% mutate(abs.value = abs(value)) %>% top_n(15, abs.value) %>%
  arrange(desc(value))
```

this topic seems to be related to the collegues.

```{r}
pros.3 <- data.frame(keyName = names(
  lsa.pros$features[, 3]),
  value = lsa.pros$features[, 3],
  row.names = NULL
)

pros.3 %>% mutate(abs.value = abs(value)) %>% top_n(15, abs.value) %>%
  arrange(desc(value))
```

this topic seems to be related to the holidays and days off

## Word Embedding & Glove
Here we will also try to model using embedding and glove

The glove below can take 5 minutes or more depending on the computer that you have so please run with caution!

```{r}
# Tried windows 5,4,3 and 4 seems reasonable
tokens.pros.clean_fcm <- fcm(
  tokens.pros.clean,
  context = "window",
  count = "weighted",
  window = 4,
  weights = 1 / (1:4),
  tri = FALSE
)

# with embedding for cons
tokens.cons.clean_fcm <- fcm(
  tokens.cons.clean,
  context = "window",
  count = "weighted",
  window = 4,
  weights = 1 / (1:4),
  tri = FALSE
)
```


```{r}
# Result matrix
results_glove <- expand.grid(
  "method" = c("Glove"),
  "input" = c("FCM"),
  "dimPos" = c(5, 20, 50),
  "dimCons" = c(5, 20, 50),
  "learner" = c("RF"),
  "RMSE" = NA,
  # NA columns for our future calculations
  stringsAsFactors = FALSE
) %>%
  arrange(dimPos, dimCons)
```


```{r}
library(text2vec)
# Compute the RMSE for each combination of #Topic for pros and cons
for (i in 1:nrow(results_glove)) {
    # Giving dimensions to the embedding
    glove_pros <- GlobalVectors$new(rank = results_glove$dimPos[i], x_max = 1)
    glove_cons <- GlobalVectors$new(rank = results_glove$dimCons[i], x_max = 1)
    
    # fitting the model, with the targets in mind
    word_vectors_main_pro <-
      glove_pros$fit_transform(tokens.pros.clean_fcm, n_iter = 50)
    print(paste("Iteration for pros at:",results_glove$dimPos[i]))
    
    word_vectors_main_cons <-
      glove_cons$fit_transform(tokens.cons.clean_fcm, n_iter = 50)
    print(paste("Iteration for cons at:",results_glove$dimCons[i]))

    # Taking out the context of the model
    word_vectors_context_pros <- glove_pros$components
    word_vectors_context_cons <- glove_cons$components
    
    # Adding the target + transpose of the context words
    reviews_glove_pro <-
      word_vectors_main_pro + t(word_vectors_context_pros)
    reviews_glove_con <-
      word_vectors_main_cons + t(word_vectors_context_cons)
    
    # number of documents which is the same for both
    ndoc <- length(tokens.pros.clean)
    
    # looking at the centers of pros and cons
    centers_pros <-
      matrix(nr = ndoc, nc = results_glove$dimPos[i]) # document embedding matrix
    centers_cons <-
      matrix(nr = ndoc, nc = results_glove$dimCons[i]) # document embedding matrix
    
    for (f in 1:ndoc) {
      words_in_f_p <-
        reviews_glove_pro[tokens.pros.clean[[f]], , drop = FALSE]
      
      centers_pros[f, ] <- apply(words_in_f_p, 2, mean)
      
      words_in_f_c <-
        reviews_glove_con[tokens.cons.clean[[f]], , drop = FALSE]
      
      centers_cons[f, ] <- apply(words_in_f_c, 2, mean)
    }
    
    row.names(centers_pros) <- names(tokens.pros.clean)
    row.names(centers_cons) <- names(tokens.cons.clean)
    
    df <- data.frame(
      Score = y,
      X1 = centers_pros,
      X2 = centers_cons,
      total_sen_score = rowSums(docvars(
        tokens.pros.clean, c("pro_sen_score", "cons_sen_score")
      )),
      total_word_count = rowMeans(docvars(
        tokens.pros.clean, c("pros_w_count", "cons_w_count")
      ))) #here we take the mean words instead of the sum as it worked better
    
    df.tr <- df[index.tr, ]
    df.te <- df[-index.tr, ]

    #RF
    reviews.rf <- ranger(Score ~ .,
                         data = df.tr)
    pred.rf <- predict(reviews.rf, df.te)$predictions
    results_glove$RMSE[i] <- sqrt(mean((pred.rf - df.te$Score) ^ 2))
  }
```

```{r}
results_glove %>%
  arrange(RMSE)
```

glove is not as good as LSA.
