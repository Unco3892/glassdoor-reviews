# Data
* Method: Scrapping
* Website: [Glassdoor.com](http://glassdoor.com/) 
* Data: Reviews in English from five major banks, namely [JP Morgan](https://www.jpmorgan.com/CH/en/about-us), [Deutsche Bank](https://www.db.com/index?language_id=1), [TD](https://www.td.com/ca/en/about-td/), [HSBC Holdings](HSBC Holdings) and [UBS](https://www.ubs.com/).

```{r, include=FALSE}
# Loading packages and knitr options
source(here::here("scripts/setup.R"))

# Importing the data
bank_reviews <- read_csv(here::here("data/Bank_reviews_processed.csv"))
```

## Data Acquisition
Our process of data acquisition was composed of the following steps:
1. First, we identified the html tags required with the information suitable for the purpose of this analysis, and prepared a script (`scripts/glassdoor-html`) in charge of identifying the desired tags and combined all of the reviews for a company into a single tibble. We also tried to account for any parsing errors that may happen as the html tags of the website were consistently updated.

2. Next, we used another script (`scripts\web-scraper`) and created a vector with the URL of the five desired companies. Once defining the minimum number of required reviews, which was **5,010** per company, we looped over each page of the review and combined all the results for the five banks into a single tibble. In order to have issues accessing the website a several times (i.e. being blocked by the company), we have defined a `rnorm_sleep_generator` which introduces random pauses between each visit replicating a human's browsing behaviors.

3. Finally, we remove any duplicates, parse the review time and finished by writing our CSV file with bank's processed reviews. A sample of the website and the tags during the scrapping process can be found in `data\glass-door-sample.html`.

## Preprocessing

### Definitions

`Corpus` = All reviews on Glassdoor for five major banks

`Text` = Reviews for each bank falls in this category; in the EDA section, we have used the five banks as the `Document`. however, in the context of unsupervised and supervised learning, we will refer to the reviews themselves and consider each individual review rather than aggregating them.

ilia: is what I have written above make sense?

`Tokens` = Words in each review

### Data structure

```{r}
bank_reviews %>% kable_head()
```

<br />
The dataset consists of `r length(unique(bank_reviews$company))` banks which are `r unique(bank_reviews$company) %>% paste(.,collapse = ", ")`. We also remark that employer rating is always filled, but this is not true for the other ratings, such as work life balance, that employee choose or not to answer.
<br />

### Checking for NAs and duplicates.

```{r,echo=FALSE}
freq.na(bank_reviews) %>% kable_maker(caption="Overview of the missing values",col.names=c("Number of missing values","%")) 
```

<br />
As mentionned above, not all ratings are mandatory to be filled, for example the diversity inclusion is mostly not considered. This indicates that we wont be able to use all of these variables for further classifiation tasks.
<br />

```{r, echo=FALSE, results='hide'}
#sum(duplicated(bank_reviews$review_id)) #The output shows that 429 reviews are duplicated, let's check them

# All the row's who values are duplicated
bank_reviews %>%
filter(duplicated(review_id))

# These are all the duplicated values
bank_reviews %>% group_by(review_id) %>% filter(n()>1) %>% ungroup() %>% kable_head()

# We look at a specific example
#bank_reviews %>% filter(review_id == "empReview_38099527")

# We will remove these rows
bank_reviews %<>%
  filter(!duplicated(review_id))

# We confirm that the duplicates are no longer there
#bank_reviews %>% filter(review_id == "empReview_38099527")
```

<br />
For unknown reasons, some reviews seem to have been duplicated, approximately 429. We remove these instances from our dataset to ensure its good quality. 
<br />

### General overview
```{r, warning=FALSE, message=FALSE}
bank_reviews %>%
  select(company, employer_rating:senior_management) %>%
  group_by(company) %>%
  add_count() %>%
  summarize_if(is.numeric,
               c(
                 "mean" = function(x)
                   mean(x, na.rm = TRUE)
                 # "median" = function(x)
                 #   median(x, na.rm = TRUE)
               )) %>%
  # relocate(company, n_median) %>%
  # rename("number of reviews" = n_median) %>%
  kable_maker(col.names=c("Bank name",
                          "Number of reviews",
                          "Rating",
                          "Work life balance",
                          "Culture values",
                          "Diversity inclusion",
                          "Career Opportunities",
                          "Compensations and benefits",
                          "Senior management"),caption="Overview of average scores")
```


```{r, warning=FALSE, message=FALSE}
# calculating the mean number of words
mean_words_cal <- function(a_word_column) {
  mean(sapply(str_count(as.character(a_word_column), '\\w+'), sum))
}

median_words_cal <- function(a_word_column) {
  median(sapply(str_count(as.character(a_word_column), '\\w+'), sum))
}



quantile_fun <- function(a_word_column,a_quantile) {
  quantile(sapply(str_count(as.character(a_word_column), '\\w+'), sum), a_quantile, na.rm = TRUE)
}

# applying the function to the two word columns
bank_reviews %>% group_by(company) %>%
  summarize(across(
    c(employer_pros, employer_cons),
    c(
      "1st_Qu." = function(x)quantile_fun(x, 0.25),
      "Median" = median_words_cal,
      "Mean" = mean_words_cal,
      "3rd_Qu." = function(x) quantile_fun(x, 0.75)
    )
  )) %>%
  gather(metric, val, 2:ncol(.)) %>%
  spread(company, val) %>% 
  kable_maker(caption="Pros and cons review word length: comparison between banks")

```

<br />
Regarding the number of words per bank for the reviews, we cannot identify interesting patterns. If we look at the median and the mean number of words for cons reviews, we do not find similar results compared to the scores. It would have been interesting to see that longer cons reviews are correlated with bad score, as angry employees would emphasize the negative points of the company instead of the positive, but this is not the case here. We can use this information later in the modeling part to only work with the reviews that our long enough and not only a few passive words enriching our analysis.
<br />

```{r fig3, fig.width = 6, fig.asp = .72,out.width = "75%"}
count_words_cal <- function(a_word_column) {
  sapply(str_count(as.character(a_word_column), '\\w+'), sum)
}

plot_1<-bank_reviews %>%
  mutate(word=count_words_cal(employer_pros)) %>%
  group_by(word) %>%
  summarise(n=n()) %>%
  filter(word<50) %>%
  ggplot(aes(x=word,y=n)) +
  geom_col() +
  ylab("Number of reviews") +
  xlab("Number of words") +
  labs(title="Pros")+
  geom_vline(xintercept = 10)

plot_2<-bank_reviews %>%
  mutate(word=count_words_cal(employer_cons)) %>%
  group_by(company,word) %>%
  summarise(n=n(),company) %>%
  filter(word<50) %>%
  ggplot(aes(x=word,y=n)) +
  geom_col() +
  ylab("") +
  xlab("Number of words") +
  labs(title="Cons") +
  geom_vline(xintercept = 10)

ggarrange(plot_1,plot_2,
          ncol=2,nrow=1)
```

<br />
Both graphs above clearly show that the number of word per review is quite concentrated around 5-6 words. This result is not surprising, as every new Glassdoor member need to write minimum length pro and con reviews for account validation. Most of them write a very short review.
<br />

```{r, cache= TRUE}
# We save the data to be evaluated to be used again in the eda
save(bank_reviews, file= here::here("data/cleaned-reviews.RData"))
```